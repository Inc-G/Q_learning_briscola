{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import environment as env\n",
    "import briscola_players as players\n",
    "import simulate_games as sim_games\n",
    "import module_next_states as next_states\n",
    "\n",
    "import importlib\n",
    "\n",
    "number_of_rounds = 20\n",
    "\n",
    "semi = ['bastoni', 'coppe', 'denari', 'spade']\n",
    "numeri = ['2', '3', '4', '5', '6', '7', '8', '9', '0', '1']\n",
    "my_points = [ 0, 10, 0, 0, 0, 0, 2, 3, 4, 11]\n",
    "my_cards = pd.DataFrame({i:[1 for j in numeri] for i in semi}, index = numeri)\n",
    "my_cards['points'] = my_points\n",
    "sorted_cards = my_cards.sort_values(by = ['points'], ascending = False)\n",
    "sorted_cards\n",
    "\n",
    "cards_in_string = [numero+seme for numero in numeri for seme in semi]\n",
    "\n",
    "all_cards_in_strings = [i + j for i in numeri for j in semi]\n",
    "all_cards_in_strings.append('None')\n",
    "sorted_cards_in_string = sorted(all_cards_in_strings)\n",
    "all_cards_in_strings_set = set(all_cards_in_strings)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes = sorted_cards_in_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer2 = tf.keras.optimizers.Adam(clipnorm = 1.)\n",
    "\n",
    "def training(model, batch_of_games, target_q_val, past_loss = None):\n",
    "    '''\n",
    "    batch of games is of shape (batch_size, 20, #features for a game)\n",
    "    '''\n",
    "    batch_of_games = batch_of_games[:,:number_of_rounds,:]\n",
    "    mask = create_mask(batch_of_games) \n",
    "    \n",
    "    to_encode_the_games = np.reshape(batch_of_games, (batch_of_games.shape[0]*batch_of_games.shape[1], batch_of_games.shape[2]))\n",
    "    \n",
    "    #since the bach of games still contains ['pl 2 hand 1', 'pl 2 hand 2', 'pl 2 hand 3', 'played card'], we get rid of this columns using before_encoding_a_game \n",
    "    encode_games = next_states.encode_a_game(next_states.before_encoding_a_game(to_encode_the_games)) #(batch_size, 20, #features for encoded game)\n",
    "    encode_games = np.reshape(encode_games, (batch_of_games.shape[0], batch_of_games.shape[1], encode_games.shape[1]))    \n",
    "    with tf.GradientTape() as tape:\n",
    "        _, all_Q_values = model(encode_games, my_return_sequences = True) #(batch_size, 20, 3)\n",
    "        Q_values = all_Q_values*mask #(batch_size, 20, 3)\n",
    "        final_q_values = tf.reduce_max(Q_values, axis = -1) #(batch_size, 20)\n",
    "        transposed_final_q_val = tf.transpose(final_q_values)\n",
    "        transposed_target = tf.transpose(target_q_val)\n",
    "        loss =  loss_fn(transposed_target, transposed_final_q_val) #transposed is useful only if you want to put weights with sample_weight\n",
    "        if past_loss != None:\n",
    "            past_loss.append(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer2.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    if past_loss != None:\n",
    "        return past_loss\n",
    "    \n",
    "    \n",
    "def create_mask(batch_of_games):\n",
    "    '''\n",
    "    Creates a mask of shape (batch_size, 20, 3).\n",
    "    \n",
    "    The entry [0,0,:] is [0.,1.,0.] means in the game at batch 0 at the hand 0 pl1 played card at position 2\n",
    "    '''\n",
    "    batch_of_games = batch_of_games[:,:number_of_rounds,:]\n",
    "    def select_card(array):\n",
    "        hand = array[1:4]\n",
    "        card = array[10]\n",
    "        location = np.where(hand == card)[0][0]\n",
    "        return np.eye(3)[location]\n",
    "    reshaped_batch = np.reshape(batch_of_games,\n",
    "                                (batch_of_games.shape[0]*batch_of_games.shape[1], batch_of_games.shape[2]))\n",
    "    which_action = np.apply_along_axis(select_card, -1, reshaped_batch)\n",
    "    return np.reshape(which_action, (batch_of_games.shape[0], batch_of_games.shape[1], 3))[:,:number_of_rounds,:]\n",
    "    \n",
    "    \n",
    "def select_batch_of_games(all_games, batch_size):\n",
    "    '''\n",
    "    Creates a batch of games of batch size.\n",
    "    \n",
    "    Drops the last round from each game (the one with the empty hand)\n",
    "    '''\n",
    "    number_of_games = int(all_games.shape[0]/(number_of_rounds+1))#Recall: Assumes there are 21 rounds\n",
    "    reshaped_games = np.reshape(all_games, (number_of_games, number_of_rounds+1, all_games.shape[1]))\n",
    "    if batch_size > number_of_games:\n",
    "        return reshaped_games\n",
    "    else:\n",
    "        indices = np.random.choice(number_of_games, batch_size, replace = False)\n",
    "        return reshaped_games[indices,:,:]\n",
    "    \n",
    "    \n",
    "def get_previous_outputs(model, batch_of_games):#checked 1 time, returns correct shapes\n",
    "    '''\n",
    "    batch of games is of shape (batch_size, 20, #features for a game)\n",
    "    '''    \n",
    "    batch_of_games = batch_of_games[:,:number_of_rounds,:]\n",
    "    to_encode_the_games = np.reshape(batch_of_games, (batch_of_games.shape[0]*batch_of_games.shape[1], batch_of_games.shape[2]))\n",
    "    \n",
    "    #since the bach of games still contains ['pl 2 hand 1', 'pl 2 hand 2', 'pl 2 hand 3', 'played card'], we get rid of this columns using before_encoding_a_game \n",
    "    encode_games = next_states.encode_a_game(next_states.before_encoding_a_game(to_encode_the_games)) #(batch_size, 20, #features for encoded game)\n",
    "    encode_games = np.reshape(encode_games, (batch_of_games.shape[0], batch_of_games.shape[1], encode_games.shape[1]))\n",
    "    \n",
    "    initial_states, _ = model(encode_games, my_return_sequences = True)\n",
    "    return initial_states #a list of initial_states of the form (batch_size, 20, result_gru_layers = 200)\n",
    "\n",
    "\n",
    "def get_target_qvals(model, batch_of_games, previous_outputs):\n",
    "    '''\n",
    "    batch of games is of shape (batch_size, 20, #features for a game)\n",
    "    \n",
    "    returns result of shape (batch_size, 20)\n",
    "    '''\n",
    "    full_batch_of_games = batch_of_games\n",
    "    batch_of_games = full_batch_of_games[:,:number_of_rounds,:]\n",
    "    \n",
    "    next_state = next_states.get_new_single_state_from_a_batch_of_games(full_batch_of_games) #(batch_size, 20, 1, #features for next_states)\n",
    "    \n",
    "    #encode next state\n",
    "    to_encode_the_games = np.reshape(next_state, (next_state.shape[0]*next_state.shape[1]*next_state.shape[2],\n",
    "                                                      next_state.shape[3]))\n",
    "    encode_games = next_states.encode_a_game(to_encode_the_games) #(batch_size*20,  #features for encoded game)\n",
    "    \n",
    "    ##SHOULD BE UPDATED: reshape outputs previous hand to have shape #(batch_size, 20, 1, #features for next_states).\n",
    "    #This is useful if to estimate the target q-val we use the average of the prob of winning for the next\n",
    "    #50 states say, rather than next single (one) state. Now it is useless\n",
    "    list_reshaped_outputs = []\n",
    "    for output in previous_outputs:\n",
    "        #repeated_output = tf.repeat(output, 50, axis = 1) useless now, se comment above\n",
    "        reshaped_output = tf.reshape(output, (output.shape[0], output.shape[1], 1, output.shape[2]))\n",
    "        list_reshaped_outputs.append(reshaped_output[:,:number_of_rounds,:,:])\n",
    "    \n",
    "    ##compute all q-vals\n",
    "    list_reshaped_outputs_nn = []\n",
    "    for output in list_reshaped_outputs:\n",
    "        reshaped_previous_output_nn = tf.reshape(output, (previous_outputs[0].shape[0] * number_of_rounds, previous_outputs[0].shape[2]) )\n",
    "        list_reshaped_outputs_nn.append(reshaped_previous_output_nn)\n",
    "        \n",
    "    reshaped_encode_games_nn = tf.reshape(encode_games, (encode_games.shape[0], 1, encode_games.shape[1]))\n",
    "    _, q_vals = model(reshaped_encode_games_nn, initial_states = list_reshaped_outputs_nn)\n",
    "    \n",
    "    shape_q_vals = [next_state.shape[0], next_state.shape[1], next_state.shape[2], 3]\n",
    "    all_q_vals = tf.reshape(q_vals, (shape_q_vals))\n",
    "    \n",
    "    ##compute max q-val\n",
    "    #compute max along 3rd axis, shape = (batch_size, 20, 50)\n",
    "    max_q_vals = tf.math.reduce_max(all_q_vals, axis = -1)\n",
    "    \n",
    "    #average along 2nd axis, shape = (batch_size, 20)\n",
    "    target_q_vals = tf.math.reduce_mean(max_q_vals, axis = -1)\n",
    "    return target_q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to save the model with the custom final layer\n",
    "class MyModel_save(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel_save, self).__init__()\n",
    "        self.gru1 = tf.keras.layers.GRU(200, return_sequences = True)\n",
    "        self.gru2 = tf.keras.layers.GRU(200, return_sequences = True)\n",
    "        self.gru3 = tf.keras.layers.GRU(200, return_sequences = True)\n",
    "        self.gru4 = tf.keras.layers.GRU(200, return_sequences = True)\n",
    "        self.dense = tf.keras.layers.Dense(3, activation = \"sigmoid\")\n",
    "\n",
    "    def call(self, state):\n",
    "            h_1 = self.gru1(state)#initial states has shape (batch_size, 200) mortacci a tf che non lo scrive\n",
    "            h_2 = self.gru2(h_1)\n",
    "            h_3 = self.gru3(h_2)\n",
    "            h_4 = self.gru4(h_3)\n",
    "            final_output = self.dense(h_4[:,-1,:])\n",
    "            return final_output\n",
    "\n",
    "def my_save_weights(trained_model, location = 'location'):\n",
    "    saving_model = MyModel_save()\n",
    "    saving_model.compile()\n",
    "\n",
    "    ## initialize weights\n",
    "    a = np.linspace(1,100,250)[np.newaxis][np.newaxis]\n",
    "    saving_model(a)\n",
    "\n",
    "    ## set weights\n",
    "    saving_model.set_weights(trained_model.get_weights())\n",
    "\n",
    "    ## save model\n",
    "    saving_model.save(location, save_format=\"tf\")\n",
    "\n",
    "\n",
    "\n",
    "def my_load_weights(to_be_trained_model, location = 'location'):\n",
    "    ## initialize weights\n",
    "    a = np.linspace(1,100,250)[np.newaxis][np.newaxis]\n",
    "    to_be_trained_model(a)\n",
    "\n",
    "    ##load weights\n",
    "    loaded_model = tf.keras.models.load_model(location)\n",
    "\n",
    "    ## set weights\n",
    "    to_be_trained_model.set_weights(loaded_model.get_weights())\n",
    "    return to_be_trained_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample training loop. See README for the details on how my model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Main, loss without sample weights\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "player_1 = players.DeepPlayer\n",
    "player_2 = players.DeterministicPlayer\n",
    "\n",
    "my_model = players.MyModel()\n",
    "my_model.compile()\n",
    "\n",
    "model_copy = players.MyModel()\n",
    "model_copy.compile()\n",
    "\n",
    "partita = env.Briscola_env()\n",
    "#print(sim_games.simulate_games(200, player_1, player_2, partita))\n",
    "\n",
    "my_games = sim_games.simulate_games_and_record_data(100, player_1, player_2, partita, epsilon = .2, pl_1_model = my_model)\n",
    "next_50_games = sim_games.simulate_games_and_record_data(50, player_1, player_2, partita, epsilon = .2, pl_1_model = model_copy)\n",
    "my_games = np.concatenate([my_games,next_50_games], axis = 0)\n",
    "\n",
    "my_model.set_weights(model_copy.get_weights())\n",
    "\n",
    "#with these parameters the expected number of times a game is selected is 6. In general it is (b size/number of new games at each episode)\n",
    "\n",
    "top_score = 0.132\n",
    "\n",
    "past_loss = []\n",
    "fractions_games_lost_vs_random = []\n",
    "fractions_games_lost_vs_det = []\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "for episode in range(5000):\n",
    "    if episode < 2500:\n",
    "        next_50_games = sim_games.simulate_games_and_record_data(50, player_1, player_2, partita, epsilon = .2, pl_1_model = my_model)\n",
    "    elif episode%10 == 0 and episode%500 > 100:            \n",
    "        next_50_games = sim_games.simulate_games_and_record_data(50, player_1, player_2, partita, epsilon = .15 if episode < 7500 else .1, pl_1_model = my_model)\n",
    "        my_games = np.concatenate([my_games,next_50_games], axis = 0)\n",
    "    \n",
    "    if my_games.shape[0] > 2100000:\n",
    "        my_games = my_games[-2100000:,:]\n",
    "        \n",
    "    batch = select_batch_of_games(my_games, batch_size)\n",
    "    \n",
    "    prev_outputs = get_previous_outputs(model_copy, batch)\n",
    "    \n",
    "    tar_q_val = get_target_qvals(model_copy, batch, prev_outputs)\n",
    "    past_loss = training(model_copy, batch, tar_q_val, past_loss)\n",
    "    \n",
    "    ##metrics\n",
    "    if episode%50 == 0 and episode > 1:\n",
    "        a = pd.DataFrame(past_loss, columns = ['loss']).rolling(window = 100).mean()\n",
    "        my_plot = a.plot(figsize = (18,12))\n",
    "        plt.show()\n",
    "        \n",
    "    if episode%500 == 0:\n",
    "        my_model.set_weights(model_copy.get_weights())\n",
    "        print('-----------------------------------------------')\n",
    "        print('Episode:', episode)\n",
    "        print('-----------------------------------------------')\n",
    "        player1 = players.DeepPlayer\n",
    "        randompl = players.RandomPlayer\n",
    "        det_pl = players.DeterministicPlayer\n",
    "        \n",
    "        lost_vs_random = sim_games.simulate_games(500, player1, randompl, partita, pl_1_model = my_model)\n",
    "        fractions_games_lost_vs_random.append(lost_vs_random)\n",
    "        \n",
    "        lost_vs_det_np = sim_games.simulate_games_and_record_data(500, player1, det_pl, partita, pl_1_model = my_model)\n",
    "        my_games = np.concatenate([my_games,lost_vs_det_np], axis = 0)\n",
    "        lost_vs_det = sim_games.how_many_lost_games(lost_vs_det_np)\n",
    "        \n",
    "        fractions_games_lost_vs_det.append(lost_vs_det)\n",
    "        \n",
    "        #Save the model if we outperform the previous model        \n",
    "        if lost_vs_random < top_score:\n",
    "            top_score = lost_vs_random\n",
    "            print('-----------------------------------------------')\n",
    "            print(\"New top score:\", lost_vs_random)\n",
    "            print('-----------------------------------------------')\n",
    "            my_save_weights(my_model, 'model_top_accuracy')\n",
    "            \n",
    "        print('-----------------------------------------------')\n",
    "        print('Last result vs random:', lost_vs_random)\n",
    "        print('Last result vs det:', lost_vs_det)\n",
    "        print('-----------------------------------------------')\n",
    "        b = pd.DataFrame([fractions_games_lost_vs_random, fractions_games_lost_vs_det], index = ['lost vs random', 'lost vs det' ]).transpose()\n",
    "        my_second_plot = b.plot(figsize = (18,12))\n",
    "        my_second_plot.axhline(0.3)\n",
    "        my_second_plot.axhline(0.2)\n",
    "        my_second_plot.axhline(0.1)\n",
    "        plt.show()\n",
    "        \n",
    "        if episode%500 == 0 and episode > 5000:\n",
    "            c1 = pd.DataFrame([fractions_games_lost_vs_random, fractions_games_lost_vs_det], index = ['lost vs random', 'lost vs det' ]).transpose()\n",
    "            c = c1.rolling(window = 10).mean()\n",
    "            my_third_plot = c.plot(figsize = (18,12))\n",
    "            my_third_plot.axhline(0.3)\n",
    "            my_third_plot.axhline(0.2)\n",
    "            my_third_plot.axhline(0.1)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
